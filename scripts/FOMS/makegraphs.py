#!/usr/local/bin/python

import sys, os, re, glob
import sklearn
from sklearn.metrics import roc_curve
from sklearn.metrics.base import _average_binary_score
from sklearn.metrics import auc
import collections
import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt
from scipy.stats import hypergeom
import numpy as np

def roc_auc_score(y_true, y_score, average="macro", sample_weight=None,
                  max_fpr=None):
    """Compute Area Under the Curve (AUC) from prediction scores

    Note: this implementation is restricted to the binary classification task
    or multilabel classification task in label indicator format.

    Parameters
    ----------
    y_true : array, shape = [n_samples] or [n_samples, n_classes]
        True binary labels in binary label indicators.

    y_score : array, shape = [n_samples] or [n_samples, n_classes]
        Target scores, can either be probability estimates of the positive
        class, confidence values, or binary decisions.

    average : string, [None, 'micro', 'macro' (default), 'samples', 'weighted']
        If ``None``, the scores for each class are returned. Otherwise,
        this determines the type of averaging performed on the data:

        ``'micro'``:
            Calculate metrics globally by considering each element of the label
            indicator matrix as a label.
        ``'macro'``:
            Calculate metrics for each label, and find their unweighted
            mean.  This does not take label imbalance into account.
        ``'weighted'``:
            Calculate metrics for each label, and find their average, weighted
            by support (the number of true instances for each label).
        ``'samples'``:
            Calculate metrics for each instance, and find their average.

    sample_weight : array-like of shape = [n_samples], optional
        Sample weights.

    max_fpr : float, optional
       If not ``None``, the standardized partial AUC over
       the range [0, max_fpr] is returned.

    Returns
    -------
    auc : float

    References
    ----------
    .. [1] `Wikipedia entry for the Receiver operating characteristic
            <http://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_

    .. [2] `Analyzing a portion of the ROC curve. McClish, 1989
            <http://www.ncbi.nlm.nih.gov/pubmed/2668680>`_

    See also
    --------
    average_precision_score : Area under the precision-recall curve

    roc_curve : Compute Receiver operating characteristic (ROC)

    Examples
    --------
    >>> import numpy as np
    >>> from sklearn.metrics import roc_auc_score
    >>> y_true = np.array([0, 0, 1, 1])
    >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])
    >>> roc_auc_score(y_true, y_scores)
    0.75

    """
    def _binary_roc_auc_score(y_true, y_score, sample_weight=None,
                              max_fpr=max_fpr):
        if len(np.unique(y_true)) != 2:
            raise ValueError("Only one class present in y_true. ROC AUC score "
                             "is not defined in that case.")

        fpr, tpr, tresholds = roc_curve(y_true, y_score,
                                        sample_weight=sample_weight)
        if max_fpr:
            idx = np.where(fpr <= max_fpr)[0]

            # linearly interpolate the ROC curve until max_fpr
            idx_last = idx.max()
            idx_next = idx_last + 1
            xc = [fpr[idx_last], fpr[idx_next]]
            yc = [tpr[idx_last], fpr[idx_next]]
            tpr = np.r_[tpr[idx], np.interp(max_fpr, xc, yc)]
            fpr = np.r_[fpr[idx], max_fpr]
            partial_roc = auc(fpr, tpr, reorder=True)

            # standardize result to lie between 0.5 and 1
            min_area = max_fpr**2/2
            max_area = max_fpr
            return 0.5*(1+(partial_roc-min_area)/(max_area-min_area))

        return auc(fpr, tpr, reorder=True)

    return _average_binary_score(
        _binary_roc_auc_score, y_true, y_score, average,
        sample_weight=sample_weight)



'''
Make graphs from the output generated by collectdata.py
Takes a directory.

For each fragment:
ROC curves of rdkit, VAMS, FOMS ligand and FOMS ligand-receptor
TPR/FPR points for shape constraints - style pareto frontier differently?

bar graphs of aucs? comparison between fragments?
'''

def getroc(decoys, actives, isdistance, computemore):
    '''given a decoys and actives file return ROC curve points and auc'''
    ytrue = []
    yscore = []
    for line in open(actives):
        vals = line.split()
        if len(vals) >= 2:
            s = float(vals[1])
            if isdistance: s = -s;
            yscore.append(s)
            ytrue.append(1)
    for line in open(decoys):
        vals = line.split()
        if len(vals) >= 2:
            s = float(vals[1])
            if isdistance: s = -s;
            yscore.append(s)
            ytrue.append(0)
        
    fpr, tpr, thresholds = roc_curve(ytrue, yscore)
    aucval = roc_auc_score(ytrue, yscore)
    
    if not computemore:
        return (fpr,tpr,aucval,[])

    
    maxfprs = [0.01,0.05,0.1,None]
    aucs = dict()
    for maxfpr in maxfprs:
        score = roc_auc_score(ytrue,yscore,max_fpr=maxfpr)
        aucs[maxfpr] = score
    
    #calculate confidence interval
    #http://stackoverflow.com/questions/19124239/scikit-learn-roc-curve-with-confidence-intervals
    i = 0
    bootscores = collections.defaultdict(list)
    ytrue = np.array(ytrue)
    yscore = np.array(yscore)
    while i < 2000:
        indices = np.random.random_integers(0,len(ytrue)-1,len(ytrue))
        if len(np.unique(ytrue[indices])) < 2:
            # We need at least one positive and one negative sample for ROC AUC
            # to be defined: reject the sample
            continue
        i += 1
        
        for maxfpr in maxfprs:
            score = roc_auc_score(ytrue[indices],yscore[indices],max_fpr=maxfpr)
            bootscores[maxfpr].append(score)
    
    cis = []
    for f in bootscores.keys():
        bscores = np.array(sorted(bootscores[f]))
        confidence_lower = bscores[int(0.05 * len(bscores))]
        confidence_upper = bscores[int(0.95 * len(bscores))]
        fval = f if f != None else 1.0
        cis.append((fval,aucs[f],confidence_lower,confidence_upper))

    return (fpr,tpr,aucval,cis)



def checkfiles(files):
    '''check that files exist'''
    for f in files:
        if not os.path.exists(f):
            print "Missing %s" %f
            sys.exit(-1)
            
def genpoints(prefix,frag):
    '''compute the fpr/tpr frome all the shape constraint search files
    in this directory with given prefix and frag'''
    acntf = 'active.%s.cnt' % frag
    dcntf = 'decoy.%s.cnt' % frag
    checkfiles([acntf,dcntf])
    numactives = float(open(acntf).read())
    numdecoys = float(open(dcntf).read())
    
    pts = list()
    cnt = 0
    files = {}
    for afile in glob.glob('%s.*.%s.actives*.out' % (prefix,frag)):
        cnt += 1.0
        dfile = afile.replace('actives','decoys')
        checkfiles([dfile])
        na = sum([1.0 for line in open(afile)])
        nd = sum([1.0 for line in open(dfile)])
        fpr = nd/numdecoys
        tpr = na/numactives
        
        if fpr > 1 or tpr > 1:
            print "BAD FPR/TPR: %.2f %2f  %s %s" % (fpr,tpr,afile,dfile)
        
        if na == 0:
            pval = 1
        else:
            pval = hypergeom.sf(na-1,numdecoys+numactives,na,nd+na)
        
        pts.append((fpr,tpr, pval))
        files[(fpr,tpr)] = afile
        #print afile,fpr,tpr, pval
            
    #bonferroni correction
    pts = np.array(list(pts))
    pts[:,2] *= cnt
    return pts, files
            

def genpareto(pts):
    '''extract out just the points on the pareto frontier'''
    pts = pts[np.lexsort((pts[:,1],pts[:,0]))] #this seems unnecessarily compliex
    besttpr = -1
    res = []
    for ((fpr,tpr, pval), f) in zip(pts,files):
        if tpr > besttpr:
            res.append((fpr,tpr, pval))
            besttpr = tpr
    return np.array(res)
            
def readtime(fname):
    '''read time from a time file and return as float'''
    f = open(fname)
    t = f.readline().split()[1]
    return float(t)
    
tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    
             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    
             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    
             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    
             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    
  
# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    
for i in range(len(tableau20)):    
    r, g, b = tableau20[i]    
    tableau20[i] = (r / 255., g / 255., b / 255.)    
mpl.rcParams['axes.color_cycle'] = tableau20[::2]
        
        
selected = set(['cathg.f3','eralpha.f3','eralpha_pot.f2','erbeta.f3','fak.f3','fxia.f4','hivrt.f4','hsp90.f2','pka.f','rho.f'])
targnames = dict(
 cathg='CathG',
eralpha=r'ER$\alpha$',
eralpha_pot='ER$\\alpha$ agonist',
erbeta=r'ER$\beta$',
fak=r'FAK',
fxia=r'FXIa',
hivrt=r'HIVrt',
hsp90=r'HSP90',
pka=r'PKA',
rho=r'Rho')

d = sys.argv[1]
d = d.rstrip('/')
os.chdir(d)
for smartf in glob.glob('smarts*'):
    smart = open(smartf).read()
    fragnum = re.findall(r'smarts(\d*)',smartf)
    frag = 'f%s' % fragnum[0]
    currsel = '%s.%s' % (d,frag)
    print currsel
    prefixes = {'foms': "FOMS",
#                'foms.rec': "FOMS Lig/Rec",
                'vams': "VAMS",
                'rdkit': "RDKit",
                'fp2': "FP2"}
    rocdata = {}
    for (p,name) in sorted(prefixes.items()):
        actives = '%s.actives.%s.out' % (p, frag)
        decoys = '%s.decoys.%s.out' % (p, frag)
        checkfiles([actives,decoys])
        fpr, tpr, aucval, cis = getroc(decoys,actives, p != 'rdkit' and not p.startswith('fp'), True)
        rocdata[p] = (fpr,tpr,aucval)
        plt.plot(fpr,tpr, linewidth=3,label="%s (AUC = %.2f)" % (name, aucval))
        
        if cis:
            cfile = open('%s.%s.ci' % (p,currsel),'w')
            for vals in cis:
                cfile.write('%f %f %f %f\n' % vals)
            cfile.close()

   # scpts = genpoints('foms.sc',frag)
    scipts, files = genpoints('foms.sciall',frag)
    
    if currsel in selected:
        pvals = scipts[:,2]
        perc = 100*np.count_nonzero(pvals < 0.01)/float(len(pvals))
        print len(pvals),len(set(pvals))
        print 'PVAL %s & %.3g & %.0f\\%% \\\\' % (targnames[d],np.min(pvals),perc)
    
   # plt.plot(scpts[0],scpts[1],'s', label="Shape Constraints")
    pareto = genpareto(scipts)
    plt.plot(pareto[:,0],pareto[:,1], 'o',markerfacecolor=tableau20[8],markeredgecolor='none',alpha=0.8,label="Interaction Point Constraints")
    plt.plot(scipts[:,0], scipts[:,1], 'o',markerfacecolor='none',markeredgecolor=tableau20[8],alpha=0.8)

    besti = np.argmin(pareto[:,2])
    bestpt = pareto[besti]
    bestf = files[(bestpt[0],bestpt[1])]
    #print bestf,frag,bestpt
    plt.gca().annotate('$p =%.3g$' % bestpt[2], xy=bestpt[0:2],xytext=(bestpt[0],bestpt[1]+0.01), fontsize=14)
    plt.gca().annotate('$p =%.3g$' % bestpt[2], xy=bestpt[0:2],xytext=(bestpt[0],bestpt[1]+0.01), fontsize=14)
        
    plt.gca().yaxis.get_major_ticks()[0].label1.set_visible(False)
    plt.legend(loc='lower right',numpoints=1)
    plt.xlabel("False Positive Rate",fontsize=18)
    plt.ylabel("True Positive Rate",fontsize=18)
    plt.savefig('%s.%s.pdf' % (d,frag),bbox_inches='tight')
    plt.close()
    
    #time plot, shape contraints as box plot, highlight best pvalue with star
    #foms,vams,rdkit as bars
    fomst = readtime('foms.%s.time' % frag)
    vamst = readtime('vams.%s.time' % frag)
    rdkitt = readtime('rdkit.%s.time' % frag)
    sctimes = []
    for tfile in glob.glob('foms.sciall.*.%s*.time' % frag):
        act = re.sub(r'_(\d+)\.time',r'.actives_\1.out',tfile)
        dec = re.sub(r'_(\d+)\.time',r'.decoys_\1.out',tfile)
        if os.path.getsize(act) > 0 or os.path.getsize(dec) > 0:
            sctimes.append(readtime(tfile))
    
    #print len(sctimes),len(glob.glob('foms.sciall.*.%s*.time' % frag))
    scave = np.mean(sctimes)
    plt.yscale('log')
    sctimes = map(lambda x: x if x > 0 else 0.01, sctimes)
    boxes = plt.boxplot(sctimes,patch_artist=True,widths=0.8)
    boxes['boxes'][0].set_facecolor(tableau20[1])
    boxes['boxes'][0].set_edgecolor('black')
    plt.setp(boxes['whiskers'], color='black',linestyle='-')
    plt.setp(boxes['caps'], color='black')
    plt.setp(boxes['medians'], color=tableau20[0])
    plt.setp(boxes['fliers'], markeredgecolor='black',alpha=0.6,marker='+')
    plt.bar([1.6,2.6,3.6],[fomst,vamst,rdkitt],bottom=0.001,color=tableau20[0])
#    plt.bar([0.6,1.6,2.6,3.6],[scave,vamst,fomst,rdkitt],bottom=0.001,color=tableau20[0])
#    plt.errorbar([1],[scave],yerr=np.std(sctimes),color='black')
    plt.xlim(0.5,4.5)
    plt.xticks(range(1,5),['Shape\nConstraints','FOMS','VAMS','RDKit'],fontsize=18)
    plt.ylabel("Time (s)",fontsize=18)
    plt.ylim(0.01,100000)
    
    bestft = readtime(re.sub(r'\.actives_(\d+).out',r'_\1.time', bestf))
    #print bestf,frag
    plt.plot([1],bestft,'o',markersize=8,alpha=0.8,color=tableau20[2])
    
    plt.savefig('%s.%s.time.pdf' % (d,frag),bbox_inches='tight')
    plt.close()
